# Primary dependency declarations for the backend.
# Run `uv pip compile backend/requirements.in --python-version 3.12 --resolution=highest --index-strategy unsafe-best-match \
#   --emit-index-url --output-file backend/requirements.txt` to refresh pins.

--index-url https://pypi.org/simple
--extra-index-url https://download.pytorch.org/whl/cu124

# Core FastAPI stack
fastapi>=0.115
uvicorn[standard]>=0.30
pydantic>=2.9
pydantic-settings>=2.5
typing_extensions>=4.12
httpx>=0.28
python-multipart>=0.0.9
uvloop>=0.19
orjson>=3.9
aiofiles>=23
redis>=5.0

# GPU/AI stack (CUDA 12.4 compatible wheels).  Explicitly request the CUDA
# builds to avoid accidentally pulling CPU-only wheels when the resolver falls
# back to PyPI.
torch==2.6.0+cu124
torchvision==0.21.0+cu124
torchaudio==2.6.0+cu124
# Triton is bundled with the torch wheels and must stay aligned with
# their expected version to avoid resolver conflicts.
triton==3.2.0

# NVIDIA NeMo toolkit for Canary ASR support
nemo_toolkit[asr]==2.1.0
accelerate>=1.1
transformers>=4.57
huggingface-hub>=0.26
vllm==0.8.5
pyannote.audio==3.4.0

# Lightning ecosystem
lightning==2.4.0
pytorch-lightning==2.4.0
torchmetrics>=1.4
pytorch-metric-learning>=2.4
lightning-utilities>=0.10

# Audio / signal processing
torch-audiomentations>=0.12
torchcodec>=0.8
librosa>=0.10
soundfile>=0.12
onnx>=1.16
cmake>=3.28

# Numeric stack
Cython>=3.0
numpy>=2.1
pybind11>=2.13
h5py>=3.11
scipy>=1.11
pandas>=2.2
scikit-learn==1.7.2
lhotse>=1.28
lilcom>=1.7
sympy==1.13.1

# Misc utilities
pooch>=1.8
msgpack>=1.0
platformdirs>=4.0
propcache>=0.4
gputil>=1.4
psutil>=5.9
openai>=1.57
openai-harmony==0.0.4
jiter>=0.11
# NVIDIA packaging uses wheel-stub as a lightweight build backend
wheel-stub>=0.4.2
opentelemetry-api>=1.26,<1.27
opentelemetry-exporter-otlp>=1.26,<1.27
prometheus-client>=0.20
jsonschema>=4.23
jsonschema-specifications>=2023
MarkupSafe>=3.0
tqdm>=4.66
packaging>=24
